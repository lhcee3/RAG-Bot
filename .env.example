# Ollama Configuration (local LLM)
OLLAMA_MODEL=llama2
OLLAMA_URL=http://localhost:11434

# Vector Store Configuration
VECTOR_DB_PATH=./chroma_db
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Chunking Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Retrieval Configuration
TOP_K_RESULTS=4

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
